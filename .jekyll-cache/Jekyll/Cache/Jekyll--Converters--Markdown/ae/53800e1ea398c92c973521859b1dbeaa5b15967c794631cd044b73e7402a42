I"R<p>다방면의 서버에서 여러가지 이유로 중복해서 호출이 일어나는 api 가 있었다. 사실 그러라고 만들어 놓은 api 이기도 했지만, 응답속도가 그리 만족스럽지는 않았던 탓인지 로직에 최적화가 되어있지 않았던 탓인지 챌린지가 많이 들어왔었다. 그래서, 응답속도와 무관하게 다방면으로 이유를 분석해서 수정을 진행했다. 효과가 좋았던 것들을 몇개 정리하기로 했다.</p>

<p align="center">
  <br /><img alt="img-name" src="/assets/images/gzip/gzip_1.png" class="content-image-1" /><br />
  <em>tps 15k</em><br />
</p>

<hr />

<h3 id="redis-cache-사이즈-줄이기"><strong>redis cache 사이즈 줄이기</strong></h3>
<ul>
  <li><strong>why</strong>
    <ul>
      <li>mongo search 속도가 느려 레디스 캐싱을 해두었는데, redis 쪽으로 네트워크 bandwidth가 너무 컸다.</li>
    </ul>
  </li>
  <li><strong>how</strong>
    <ol>
      <li>시리얼라이저를 바꿈
        <ul>
          <li>레디스 넣기 전에 snappy 를 사용했는데, gzip 으로 바꿨음</li>
        </ul>
      </li>
      <li>캐싱 데이터를 바꿈
        <ul>
          <li>특정 작업의 결과물을 캐싱하던 것에서, 사용되는 파라미터 중 변동되는 것만 캐싱하고 서버가 작업을 매번 새로 하게 함</li>
        </ul>
      </li>
    </ol>
  </li>
  <li><strong>result</strong>
    <ol>
      <li>두 작업 모두 cpu 를 손해보고 network 를 이득보는 작업이라, 효과는 확실했다. 레디스 인아웃은 500 MiB/s -&gt; 95 MiB/s 로 감소했지만, api 응답은 p50 7.5ms -&gt; 11ms 로 증가했다.</li>
    </ol>
  </li>
</ul>

<p align="center">
  <br /><img alt="img-name" src="/assets/images/gzip/gzip_2.png" class="content-image-1" /><br />
  <em>tps 15k</em><br />
</p>
:ET